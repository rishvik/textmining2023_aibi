{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "ab48cc19-0391-4151-91b9-7168e2d36c25",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import argparse\n",
    "import pandas as pd\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "import pandas as pd\n",
    "from sklearn.metrics import classification_report\n",
    "import argparse\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16ddc7cd-3c34-4685-923d-4a8cbc05b695",
   "metadata": {},
   "source": [
    "Function for the extraction of differenct features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "e6ee8385-3780-4256-b751-fae59791f944",
   "metadata": {},
   "outputs": [],
   "source": [
    "#inspire from from different documentations and stack over flow questions\n",
    "\n",
    "def wordnet_pos(pos):\n",
    "\n",
    "    if pos.startswith('J'):\n",
    "        return 'a'\n",
    "    elif pos.startswith('V'):\n",
    "        return 'v'\n",
    "    elif pos.startswith('N'):\n",
    "        return 'n'\n",
    "    elif pos.startswith('R'):\n",
    "        return 'r'\n",
    "    else:\n",
    "        return 'n'\n",
    "\n",
    "def lemma_extraction(tokens, pos_list):\n",
    "    lemmas = []\n",
    "    lem = WordNetLemmatizer()\n",
    "    for token, pos in zip(tokens, pos_list):\n",
    "        lemma = lem.lemmatize(token, wordnet_pos(pos))\n",
    "        lemmas.append(lemma)\n",
    "\n",
    "\n",
    "    return lemmas\n",
    "\n",
    "def pos_extraction(tokens):\n",
    "    pos_list = []\n",
    "    tagged = nltk.pos_tag(tokens)\n",
    "    for token, pos_tag in tagged:\n",
    "        pos_list.append(pos_tag)   \n",
    "\n",
    "    return pos_list\n",
    "\n",
    "def previous_and_next_token_extraction(tokens):\n",
    "    position_index = 0\n",
    "\n",
    "    prev_tokens = []\n",
    "    next_tokens = []\n",
    "\n",
    "    for i in range(len(tokens)):\n",
    "\n",
    "        prev_index = (position_index - 1)\n",
    "        next_index = (position_index + 1)\n",
    "\n",
    "        #previous token\n",
    "        if prev_index < 0:\n",
    "            previous_token = \"None\"\n",
    "        else: \n",
    "            previous_token = tokens[prev_index]\n",
    "\n",
    "        prev_tokens.append(previous_token)\n",
    "\n",
    "        #next token\n",
    "        if next_index < len(tokens):\n",
    "            next_token = tokens[next_index]\n",
    "        else: \n",
    "            next_token = \"None\"\n",
    "\n",
    "        next_tokens.append(next_token)\n",
    "\n",
    "        #moving to next token in list \n",
    "        position_index += 1\n",
    "\n",
    "    return prev_tokens, next_tokens\n",
    "\n",
    "\n",
    "\n",
    "def neg(tokens, neg):\n",
    "    neg_word_list = []\n",
    "\n",
    "    for token in tokens:\n",
    "\n",
    "        # label 1 if token is in negative word list\n",
    "        if token in neg:\n",
    "            label = 1\n",
    "\n",
    "        # label 0 if token is not in negative word list\n",
    "        else:\n",
    "            label = 0\n",
    "        \n",
    "        neg_word_list.append(label)\n",
    "\n",
    "    return neg_word_list"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "650d7195-be8e-4b7e-9d0f-3da154fdd07f",
   "metadata": {},
   "source": [
    "Extracting features with the help of above functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "bcfadd75-d4b7-47b6-9b2b-c0e83d0cff07",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def file(input_file):\n",
    "    # open and red file and returns token, gold labels and chapters \n",
    "    \n",
    "    df = pd.read_csv(input_file, encoding='utf-8', delimiter = \"\\t\", quotechar = '|')\n",
    "    chapters = df.iloc[:, 0]\n",
    "    sent_id = df.iloc[:, 1]\n",
    "    token_position = df.iloc[:, 2]\n",
    "    tokens = df.iloc[:, 3]\n",
    "    gold = df.iloc[:, 4]\n",
    "    \n",
    "    return tokens, gold, chapters, \n",
    "\n",
    "def write_features(tokens,gold):\n",
    "    \n",
    "    negl= ['nor', 'neither', 'without', 'nobody', 'none', 'nothing', 'never', 'not', 'no', 'nowhere', 'non']\n",
    "    #not considering at this moment, will work on the smooth implimentation of this\n",
    "    # written the code for negetion words, fucntion can be seen above\n",
    "    # had few difificulties in final processing of output \n",
    "    \n",
    "    \n",
    "    # Defining header names\n",
    "    feature_names = [\"token\",\n",
    "                \"lemma\",\n",
    "                \"pos_tag\",\n",
    "                \"prev_token\",\n",
    "                \"next_token\",\n",
    "                    \"neg\"]\n",
    "\n",
    "   # using all above mentioned functions for the extraction of features, except fucntion neg  \n",
    "    pos_tag = pos_extraction(tokens)\n",
    "    lemma = lemma_extraction(tokens, pos_tag)\n",
    "    neg_word = neg(tokens,negl)\n",
    "    prev_next_token = previous_and_next_token_extraction(tokens)\n",
    "    prev_tokens, next_token = prev_next_token\n",
    "\n",
    "    features_dict = {'token': tokens, 'pos_tag': pos_tag,'lemma': lemma,'neg_word':neg_word ,'prev_token': prev_tokens,\n",
    "                     'next_token': next_token}\n",
    "    return features_dict\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02bb2346-02d9-4b05-9e03-9a5b4f0eeaed",
   "metadata": {},
   "source": [
    "Creatinf featues list, svm model and prdictions "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "ccbee547-9119-43f0-a25a-ba5e440654fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def data(input_file):\n",
    "    \n",
    "    data = []\n",
    "    tokens, gold, chapters= file(input_file) # from def file mentioned above\n",
    "    feature_dict = write_features(tokens,gold) # from above function\n",
    "    #features \n",
    "    token = feature_dict['token']\n",
    "    lemma = feature_dict['lemma']\n",
    "    pos_tag = feature_dict['pos_tag']\n",
    "    neg_word =  feature_dict['neg_word'],\n",
    "    prev_token= feature_dict['prev_token']\n",
    "    next_token= feature_dict['next_token']\n",
    "    golds = gold.tolist() #gold labels to list\n",
    "    token = token.tolist() #tokens to list \n",
    "    \n",
    "    #print(type(next_token)\n",
    "    #,type(token),type(lemma),type(pos_tag),type(neg_word),\n",
    "    # type(prev_token),type(next_token))\n",
    "    #print(type(list(neg_word)))\n",
    "    for token,lemma,pos_tag,prev_token,next_token in zip(token,lemma,pos_tag,\n",
    "                                                                         prev_token,next_token):\n",
    "        feature_dict = {\"Tokens\": token, 'lemmas':lemma,'pos_tags':pos_tag,\n",
    "                        'prev_token':prev_token,'next_token':next_token}\n",
    "\n",
    "        #feature_dict = {\"1\": token, '2':lemma,'3':pos_tag,'4':neg_word,'5':prev_token,'6':next_token, '7': gold}\n",
    "        data.append(feature_dict)\n",
    "        #print(data)\n",
    "    return data, golds\n",
    "\n",
    "def create_classifier(train_features, train_targets: list):\n",
    "    #creating SVM model \n",
    "    \n",
    "    model = LinearSVC()\n",
    "    vec = DictVectorizer()\n",
    "    featuresv = vec.fit_transform(training_features)\n",
    "    train_targets = np.array(train_targets)\n",
    "    model.fit(featuresv, train_targets)\n",
    "\n",
    "    return model, vec\n",
    "\n",
    "\n",
    "\n",
    "def predicted(testfile, model,vec):\n",
    "    features, goldlabels = data(testfile)\n",
    "    test_features_vectorized = vec.transform(features)\n",
    "    predictions = model.predict(test_features_vectorized)\n",
    "\n",
    "    return predictions, goldlabels\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08861e67-67dc-4c02-8458-c32b88ee88f0",
   "metadata": {},
   "source": [
    "Importing Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "767096de-7600-4021-9da0-273a1a08e0dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_file = 'data/no_dev.txt'\n",
    "dev_file = 'data/dev.txt'\n",
    "test_file_1 = 'data/test_1.txt' #cardboard test\n",
    "test_file_2 = 'data/test_2.txt' #circle test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "72cda19f-17d7-40ea-bb49-7cffc074552d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'list'> <class 'list'> <class 'list'> <class 'list'> <class 'tuple'> <class 'list'> <class 'list'>\n",
      "<class 'list'>\n"
     ]
    }
   ],
   "source": [
    "#generating TRAINING FEATURES \n",
    "training_features, gold_labels= data(training_file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "20768578-a8cd-4564-9331-9f1ee7990f3e",
   "metadata": {},
   "outputs": [],
   "source": [
    " #creating model and vectorzor \n",
    "model, vec= create_classifier(training_features, gold_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "8fe79518-94c7-4f3d-b378-9152a288ae00",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'list'> <class 'list'> <class 'list'> <class 'list'> <class 'tuple'> <class 'list'> <class 'list'>\n",
      "<class 'list'>\n"
     ]
    }
   ],
   "source": [
    "# develoment predictions \n",
    "dev, gold = predicted(dev_file, model, vec)\n",
    "# test predictions 1\n",
    "test1, gold1 = predicted(test_file_1, model, vec)\n",
    "# test predictions 2\n",
    "test2, gold2 = predicted(test_file_2, model, vec)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd84a7f1-a9d8-4463-a1df-2c2cd2683ad6",
   "metadata": {},
   "source": [
    "Classification report and P,R,f-1scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "1fcfcc33-68b8-4a43-9b4d-9ce7de2f5ebe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_confusion_matrix(predictions, goldlabels):\n",
    "    # based on example from https://datatofish.com/confusion-matrix-python/\n",
    "    data = {'Gold': goldlabels, 'Predicted': predictions}\n",
    "    df = pd.DataFrame(data, columns=['Gold', 'Predicted'])\n",
    "\n",
    "    confusion_matrix = pd.crosstab(df['Gold'], df['Predicted'], rownames=['Gold'], colnames=['Predicted'])\n",
    "    print(confusion_matrix)\n",
    "    report = classification_report(goldlabels,predictions,digits = 3)\n",
    "    print('METRICS: ')\n",
    "    print()\n",
    "    print(report)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea9e232f-957e-4ac4-bc53-b76392cbed3c",
   "metadata": {},
   "source": [
    "Development se classification report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "5b0e459f-c9d7-425f-a1c0-51df88e6dcb4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted  B-NEG  I-NEG      O\n",
      "Gold                          \n",
      "B-NEG        149      0     27\n",
      "I-NEG          0      2      1\n",
      "O              6      0  13381\n",
      "METRICS: \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       B-NEG      0.961     0.847     0.900       176\n",
      "       I-NEG      1.000     0.667     0.800         3\n",
      "           O      0.998     1.000     0.999     13387\n",
      "\n",
      "    accuracy                          0.997     13566\n",
      "   macro avg      0.986     0.838     0.900     13566\n",
      "weighted avg      0.997     0.997     0.997     13566\n",
      "\n"
     ]
    }
   ],
   "source": [
    "cf_dev = print_confusion_matrix(dev,gold)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51685a1a-6c99-4148-9452-60e2f3d2d1b9",
   "metadata": {},
   "source": [
    "Test set one, classification report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "5bbfb66c-8587-4d69-8f1f-81e802e98f2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted  B-NEG      O\n",
      "Gold                   \n",
      "B-NEG        120     14\n",
      "I-NEG          0      1\n",
      "O              6  10042\n",
      "METRICS: \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       B-NEG      0.952     0.896     0.923       134\n",
      "       I-NEG      0.000     0.000     0.000         1\n",
      "           O      0.999     0.999     0.999     10048\n",
      "\n",
      "    accuracy                          0.998     10183\n",
      "   macro avg      0.650     0.632     0.641     10183\n",
      "weighted avg      0.998     0.998     0.998     10183\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/rishvikchandel/opt/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/rishvikchandel/opt/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/rishvikchandel/opt/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "cf_test_1 = print_confusion_matrix(test1,gold1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0fdfacc-a065-4e62-9f84-1530f66370a4",
   "metadata": {},
   "source": [
    "Test set two, classification report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "28857921-97c3-4747-8341-94b0c0ea4b60",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted  B-NEG     O\n",
      "Gold                  \n",
      "B-NEG        127     8\n",
      "I-NEG          0     4\n",
      "O              7  8885\n",
      "METRICS: \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       B-NEG      0.948     0.941     0.944       135\n",
      "       I-NEG      0.000     0.000     0.000         4\n",
      "           O      0.999     0.999     0.999      8892\n",
      "\n",
      "    accuracy                          0.998      9031\n",
      "   macro avg      0.649     0.647     0.648      9031\n",
      "weighted avg      0.997     0.998     0.998      9031\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/rishvikchandel/opt/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/rishvikchandel/opt/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/rishvikchandel/opt/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "cf_test_2 = print_confusion_matrix(test2,gold2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f2e2a3f-6feb-44a4-9831-e74fb2a39386",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
